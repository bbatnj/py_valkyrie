{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e56302",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run /home/bb/src/python/valkyrie/apps/common/run_notebook_import.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91defd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from itertools import product as cartesian_product\n",
    "\n",
    "from overrides import overrides\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from valkyrie.tools import *\n",
    "from valkyrie.ml import modules\n",
    "from valkyrie.ml.utils import tensor, HyperParameters\n",
    "from valkyrie.ml import utils as ml_utils\n",
    "from valkyrie.nibelungen.data import DataMgr, Df2T2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83dad404",
   "metadata": {},
   "outputs": [],
   "source": [
    "from valkyrie.ml.data import DataModule\n",
    "\n",
    "sdate, edate = '2023-01-01', '2023-01-31'\n",
    "instr = 'BDM.BTC.USDT.FP'\n",
    "freq = '1s'\n",
    "ret_n_s = [30]\n",
    "\n",
    "#########################################################\n",
    "#DataMgr\n",
    "#########################################################\n",
    "data_mgr = DataMgr(sdate, edate, freq, '/home/bb/data/BDM', instrs = ['BDM.BTC.USDT.FP'], ret_n_s = [120])\n",
    "df_res = data_mgr.get(instr) \n",
    "channels = ['bpx_last','apx_last','bq_last','aq_last','buy_qty_sum', 'sell_qty_sum']\n",
    "n_channels = len(channels)\n",
    "df2t2 = Df2T2(df_res, M = 16, xcols = channels, ycol = 'mid_last_ret_120_n')\n",
    "dm = DataModule.from_dataset(df2t2, None, 2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba3de26",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_df_mem_usage(df_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c3b693",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df2t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a501e897",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_init_loss(net, dm):\n",
    "            \n",
    "    init_loss, loss = 0.0, 0.0\n",
    "    dl = dm.get_dataloader(True)\n",
    "    for i, batch in enumerate(dl):\n",
    "        print(i)\n",
    "        print(batch[0].shape)\n",
    "        X, YW = batch[0], batch[-1]                \n",
    "        ZEROS = torch.zeros(YW.shape[0])\n",
    "        with torch.no_grad():            \n",
    "            init_loss += net.loss(ZEROS, YW)\n",
    "            Y_hat = net(X.to(ml_utils.gpu()))\n",
    "            loss += net.loss(Y_hat, YW.to(ml_utils.gpu()))\n",
    "    return init_loss, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62034c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Inception(nn.Module):\n",
    "    # c1--c4 are the number of output channels for each branch\n",
    "    def __init__(self, c1, c2, c3, c4, **kwargs):\n",
    "        super(Inception, self).__init__(**kwargs)\n",
    "        # Branch 1\n",
    "        self.b1_1 = nn.LazyConv2d(c1, kernel_size=1)\n",
    "        # Branch 2\n",
    "        self.b2_1 = nn.LazyConv2d(c2[0], kernel_size=1)\n",
    "        self.b2_2 = nn.LazyConv2d(c2[1], kernel_size=3, padding=1)\n",
    "        # Branch 3\n",
    "        self.b3_1 = nn.LazyConv2d(c3[0], kernel_size=1)\n",
    "        self.b3_2 = nn.LazyConv2d(c3[1], kernel_size=5, padding=2)\n",
    "        # Branch 4\n",
    "        self.b4_1 = nn.MaxPool2d(kernel_size=3, stride=1, padding=1)\n",
    "        self.b4_2 = nn.LazyConv2d(c4, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        b1 = F.relu(self.b1_1(x))\n",
    "        b2 = F.relu(self.b2_2(F.relu(self.b2_1(x))))\n",
    "        b3 = F.relu(self.b3_2(F.relu(self.b3_1(x))))\n",
    "        b4 = F.relu(self.b4_2(self.b4_1(x)))\n",
    "        return torch.cat((b1, b2, b3, b4), dim=1)\n",
    "        \n",
    "\n",
    "    def forward(self, x):        \n",
    "        b1 = F.relu(self.b1_1(x))\n",
    "        b2 = F.relu(self.b2_2(F.relu(self.b2_1(x))))\n",
    "        b3 = F.relu(self.b3_2(F.relu(self.b3_1(x))))\n",
    "        b4 = F.relu(self.b4_2(self.b4_1(x)))\n",
    "        return torch.cat((b1, b2, b3, b4), dim=1)\n",
    "\n",
    "class GoogleNet(modules.Regressor):\n",
    "    def b1(self):\n",
    "        return nn.Sequential(            \n",
    "            nn.LazyConv2d(64, kernel_size=7, stride=2, padding=3),\n",
    "            nn.ReLU(), nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "    \n",
    "@d2l.add_to_class(GoogleNet)\n",
    "def b2(self):\n",
    "    return nn.Sequential(        \n",
    "        nn.LazyConv2d(64, kernel_size=1), nn.ReLU(),\n",
    "        nn.LazyConv2d(192, kernel_size=3, padding=1), nn.ReLU(),\n",
    "        nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "\n",
    "@d2l.add_to_class(GoogleNet)\n",
    "def b3(self):\n",
    "    return nn.Sequential(        \n",
    "        Inception(64, (96, 128), (16, 32), 32),\n",
    "        Inception(128, (128, 192), (32, 96), 64),\n",
    "        nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "\n",
    "@d2l.add_to_class(GoogleNet)\n",
    "def b4(self):\n",
    "    return nn.Sequential(\n",
    "                         Inception(192, (96, 208), (16, 48), 64),\n",
    "                         Inception(160, (112, 224), (24, 64), 64),\n",
    "                         Inception(128, (128, 256), (24, 64), 64),\n",
    "                         Inception(112, (144, 288), (32, 64), 64),\n",
    "                         Inception(256, (160, 320), (32, 128), 128),\n",
    "                         nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "\n",
    "@d2l.add_to_class(GoogleNet)\n",
    "def b4(self):\n",
    "    return nn.Sequential(\n",
    "                         Inception(192, (96, 208), (16, 48), 64),\n",
    "                         Inception(160, (112, 224), (24, 64), 64),\n",
    "                         Inception(128, (128, 256), (24, 64), 64),\n",
    "                         Inception(112, (144, 288), (32, 64), 64),\n",
    "                         Inception(256, (160, 320), (32, 128), 128),\n",
    "                         nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "\n",
    "@d2l.add_to_class(GoogleNet)\n",
    "def b5(self):\n",
    "    return nn.Sequential(\n",
    "                         Inception(256, (160, 320), (32, 128), 128),\n",
    "                         Inception(384, (192, 384), (48, 128), 128),\n",
    "                         nn.AdaptiveAvgPool2d((1,1)), nn.Flatten())\n",
    "\n",
    "@d2l.add_to_class(GoogleNet)\n",
    "def b0(self):\n",
    "    return nn.BatchNorm2d(6);\n",
    "\n",
    "\n",
    "\n",
    "@d2l.add_to_class(GoogleNet)\n",
    "def __init__(self, lr=0.1, num_classes=10):\n",
    "    #super(GoogleNet, self).__init__()\n",
    "    \n",
    "    super(GoogleNet, self).__init__('l1')        \n",
    "    self.save_hyperparameters()\n",
    "    self.net = nn.Sequential(self.b0(), self.b1(), self.b2(), self.b3(), self.b4(),\n",
    "                             self.b5(), nn.LazyLinear(1))\n",
    "    self.net.apply(d2l.init_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5e389a",
   "metadata": {},
   "outputs": [],
   "source": [
    "google_net = GoogleNet(lr = 0.1)\n",
    "X = df2t2[0][0]\n",
    "ml_utils.layer_summary(google_net, X.shape)\n",
    "#ml_utils.parameter_summary(google_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aff9855",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = modules.Trainer(max_epochs=15, num_gpus=1)\n",
    "with Timer('training'):\n",
    "    trainer.fit(google_net, dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bf7907",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_init_loss(google_net, dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e960951",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dm.get_dataloader(train = True).dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aacf1818",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19282a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.empty(n)\n",
    "for i in np.arange(n):\n",
    "    y[i] = dataset[i][1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28911551",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.abs(y).sum()/1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01026f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "net_cpu = google_net.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c75a159",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = np.empty(n)\n",
    "for i in np.arange(n):\n",
    "    x = dataset[i][0]\n",
    "    y_hat[i] = net_cpu(x.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33655a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dataset[0:2][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c09f8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a73a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757a3759",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683c740a",
   "metadata": {},
   "outputs": [],
   "source": [
    "google_net = google_net.to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8257d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = dm.get_dataloader(True)\n",
    "y_hat_list = []\n",
    "yw_list = []\n",
    "for i, batch in enumerate(dl):    \n",
    "    X, YW = batch[0], batch[1]\n",
    "    ZEROS = torch.zeros(YW.shape[0])\n",
    "    with torch.no_grad():            \n",
    "        #init_loss += net.loss(ZEROS, YW)\n",
    "        Y_hat = google_net(X.to(ml_utils.gpu()))\n",
    "        y_hat_list.append(Y_hat.to('cpu'))\n",
    "        yw_list.append(YW)        \n",
    "        print(Y_hat)\n",
    "        #loss += net.loss(Y_hat, YW.to(ml_utils.gpu()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf31a058",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = 0.0\n",
    "loss_y = 0.0\n",
    "loss_y_hat = 0.0\n",
    "for y_hat, yw in zip(y_hat_list, yw_list):\n",
    "    y_hat = y_hat.to('cpu')\n",
    "    y = yw[:,0]\n",
    "    loss += np.mean(np.abs(y_hat - y))\n",
    "    loss_y += np.mean(np.abs(y))\n",
    "    loss_y_hat += np.mean(np.abs(y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ccf112",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5b10a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28795f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_list[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfe0517",
   "metadata": {},
   "outputs": [],
   "source": [
    "yw_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fa6524",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [yw[:,0] for yw in yw_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cef0cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af50a4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_tensor = torch.cat(y, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d55949",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = concatenated_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae08de96",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.abs().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a1daef",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605d3ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbf88b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = [y_hat.view(-1) for y_hat in y_hat_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a5894f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = torch.cat(y_hat, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98ffe71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
